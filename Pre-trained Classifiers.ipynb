{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face and Eye Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifying Python version used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifying opencv version used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\Users\\aravi\\Anaconda3\\envs\\computervision:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "libopencv                 3.4.2                h20b85fd_0  \n",
      "opencv                    3.4.2            py36h40b0b35_0  \n",
      "py-opencv                 3.4.2            py36hc319ecb_0  \n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing opencv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating cascades for face and eye with pre-trained classifiers**\n",
    "\n",
    "- The below mentioned xml files consists of stages and haar like features for detecting in those stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating cascades\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining detect function to detect faces and eyes and draw coloured rectangles to denote them**\n",
    "\n",
    "- We create a function that takes as input the image in black and white (gray) and the original image (frame), and that will return the same image with the detector rectangles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining detect function\n",
    "\n",
    "def detect(grey, image):\n",
    "    faces = face_cascade.detectMultiScale(grey,1.3,5) # (greyscale image,image compression ratio, minimum nearby frames to cross threshold)\n",
    "    for (x,y,w,h) in faces: # (x,y)- co-ordinates of rectange start point, w-width, h-height\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2) #(original-image, start, end, color, thickness)\n",
    "        roi_grey = grey[y:y+h, x:x+w] # images are cropped to detect eye within face to save computational time\n",
    "        roi_color = image[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_grey,1.1,3)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n",
    "    return image #image is returned with detector rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Capturing video and applying canvas to it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing video and applying canvas to it\n",
    "video_capture = cv2.VideoCapture(0) #0 for webcam inbuit, 1 for other source\n",
    "\n",
    "while True:\n",
    "    _,frame = video_capture.read() # first return value is True or False (status)\n",
    "    grey = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) # coloured image is converted to black and white image\n",
    "    canvas = detect(grey,frame) # frame is returned with rectangles\n",
    "    cv2.imshow('Video',canvas) #frame is shown\n",
    "    \n",
    "# '& 0xff' is used for masking with 255 as cv2.waitkey(1) will return bits and only last 8 bits are equal to \n",
    "# the ASCII value of the key pressed.\n",
    "# waitkey(1) is used as after 1milli second delay, the loop runs again and frame gets refreshed.\n",
    "    if  cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        break\n",
    "\n",
    "video_capture.release() #Webcam turned off\n",
    "cv2.destroyAllWindows() #Closing all windows with the images in it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
